# ğŸ“ Smart Document Organizer

Lokales Ablage-System mit LLM-basierten Ordner-VorschlÃ¤gen.

## ğŸ¯ Was macht das System?

1. **Dateien in Inbox werfen** â†’ System liest Inhalt
2. **3 passende Ordner werden vorgeschlagen** â†’ Du wÃ¤hlst einen
3. **Datei wird automatisch verschoben** â†’ Fertig!

Alles lÃ¤uft **lokal** auf deinem Mac mini mit Ollama.

## ğŸš€ Quick Start (lokal oder GitHub Codespaces)

```bash
# 1. Dependencies installieren
python3 -m venv .venv
source .venv/bin/activate
pip install -r NAS/requirements.txt

# 2. System starten
python3 NAS/document_organizer.py

# 3. Web-UI Ã¶ffnen
open http://localhost:8080
```

## ğŸ“‚ Ordnerstruktur

```
~/NAS/
â”œâ”€â”€ inbox/              â† Dateien hier reinwerfen
â”œâ”€â”€ ablage/
â”‚   â”œâ”€â”€ Rechnungen/
â”‚   â”œâ”€â”€ Vertraege/
â”‚   â”œâ”€â”€ Bank/
â”‚   â”œâ”€â”€ Arbeit/
â”‚   â”œâ”€â”€ Schule/
â”‚   â”œâ”€â”€ Privat/
â”‚   â”œâ”€â”€ Anleitungen/
â”‚   â”œâ”€â”€ Auto/
â”‚   â””â”€â”€ Sonstiges/
â””â”€â”€ processed/          â† System-Logs
```

## ğŸ§  LLM Requirements

- **Ollama** mit `qwen2.5:7b-instruct` oder `qwen2.5:3b-instruct` (Standard)
- LÃ¤uft komplett lokal (keine Cloud)
- Antwortet immer in strukturiertem JSON

Optional kannst du das Modell und die URL Ã¼ber Umgebungsvariablen steuern:

```bash
export OLLAMA_URL="http://localhost:11434/api/generate"
export OLLAMA_MODEL="qwen2.5:7b-instruct"
export OLLAMA_TIMEOUT=30
```

## ğŸ“ Projektstruktur

```
SmartSortierer/
â”œâ”€â”€ NAS/
â”‚   â”œâ”€â”€ document_organizer.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ setup_mac.sh
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html
â””â”€â”€ README.md
```

## âš¡ Features

- âœ… PDF/DOCX/TXT Text-Extraktion
- âœ… 3 Ordner-VorschlÃ¤ge mit BegrÃ¼ndung
- âœ… Web-UI fÃ¼r einfache Auswahl
- âœ… Automatisches File-Monitoring
- âœ… Lern-Effekt (bessere VorschlÃ¤ge Ã¼ber Zeit)
